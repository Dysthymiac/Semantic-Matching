{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "from src.config.config import MainConfig\n",
    "from src.data.coco_loader import COCOLoader\n",
    "from src.data.preprocessed_dataset import PreprocessedDataset\n",
    "from src.evaluation import load_or_compute_matching, get_identity_mapping\n",
    "from src.evaluation.detection_matching import MatchedDetection, patch_centers_in_image_space, _point_in_bbox\n",
    "from src.visualization.primitives import get_crop_bounds, compute_padding_info, patch_to_crop_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "CONFIG_PATH = Path('config_zebra_test.yaml')  # <-- change as needed\n\nconfig = MainConfig.from_yaml(CONFIG_PATH)\ndataset = PreprocessedDataset(config.output_root)\ncoco_loader = COCOLoader(config.coco_json_path, config.dataset_root)\n\ntarget_size = config.active_resize_size\npatch_size = config.active_patch_size\n\nmatched = load_or_compute_matching(\n    dataset, coco_loader, config.output_root,\n    target_size=target_size, patch_size=patch_size,\n    category_names=config.matching_categories,\n)\nprint(f'{len(matched)} matched detections')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_rects_in_image_space(det, img_w, img_h, target_size, patch_size):\n",
    "    \"\"\"Return list of (x, y, w, h) rectangles in image coordinates for each valid patch.\"\"\"\n",
    "    crop_x1, crop_y1, crop_x2, crop_y2 = get_crop_bounds(det.square_crop_bbox, img_w, img_h)\n",
    "    crop_w = crop_x2 - crop_x1\n",
    "    crop_h = crop_y2 - crop_y1\n",
    "    if crop_w <= 0 or crop_h <= 0:\n",
    "        return []\n",
    "\n",
    "    h_patches, w_patches = det.patch_mask.shape\n",
    "    rects = []\n",
    "    for i in range(h_patches):\n",
    "        for j in range(w_patches):\n",
    "            if det.patch_mask[i, j]:\n",
    "                crop_rect = patch_to_crop_coords(i, j, crop_w, crop_h, target_size, patch_size)\n",
    "                if crop_rect:\n",
    "                    cx, cy, cw, ch = crop_rect\n",
    "                    rects.append((crop_x1 + cx, crop_y1 + cy, cw, ch))\n",
    "    return rects\n",
    "\n",
    "\n",
    "def plot_detection_vs_gt(det, gt_ann, img, img_w, img_h, target_size, patch_size,\n",
    "                         ax=None, title_extra=\"\"):\n",
    "    \"\"\"Plot a single detection against a GT annotation on the image.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Patch rectangles + centers\n",
    "    patch_rects = patch_rects_in_image_space(det, img_w, img_h, target_size, patch_size)\n",
    "    centers = patch_centers_in_image_space(\n",
    "        det.square_crop_bbox, det.patch_mask, img_w, img_h, target_size, patch_size\n",
    "    )\n",
    "    inside = [_point_in_bbox(x, y, gt_ann.bbox) for x, y in centers]\n",
    "\n",
    "    for idx, (x, y, w, h) in enumerate(patch_rects):\n",
    "        color = (0.2, 0.8, 0.2) if inside[idx] else (0.8, 0.2, 0.2)\n",
    "        ax.add_patch(Rectangle((x, y), w, h, facecolor=color, alpha=0.35, edgecolor='none'))\n",
    "\n",
    "    # GT bbox (green solid)\n",
    "    gx1, gy1, gx2, gy2 = gt_ann.bbox.x1, gt_ann.bbox.y1, gt_ann.bbox.x2, gt_ann.bbox.y2\n",
    "    ax.add_patch(Rectangle((gx1, gy1), gx2 - gx1, gy2 - gy1,\n",
    "                            fill=False, edgecolor='lime', linewidth=2.5))\n",
    "\n",
    "    # Detection bbox (blue dashed)\n",
    "    dx1, dy1, dx2, dy2 = det.bbox.int().tolist()\n",
    "    ax.add_patch(Rectangle((dx1, dy1), dx2 - dx1, dy2 - dy1,\n",
    "                            fill=False, edgecolor='dodgerblue', linewidth=2.5, linestyle='--'))\n",
    "\n",
    "    n_inside = sum(inside)\n",
    "    n_total = len(inside)\n",
    "    score = n_inside / n_total if n_total > 0 else 0.0\n",
    "    ax.set_title(\n",
    "        f'score={score:.3f}  |  patches inside GT: {n_inside}/{n_total}  |  '\n",
    "        f'det={det.detection_id}{title_extra}',\n",
    "        fontsize=11,\n",
    "    )\n",
    "    ax.set_xlim(min(gx1, dx1) - 50, max(gx2, dx2) + 50)\n",
    "    ax.set_ylim(max(gy2, dy2) + 50, min(gy1, dy1) - 50)\n",
    "    ax.axis('off')\n",
    "    return score\n",
    "\n",
    "\n",
    "def plot_match(match: MatchedDetection, dataset, coco_loader, target_size, patch_size, figsize=(16, 10)):\n",
    "    \"\"\"Visualize a single detection-to-GT match.\"\"\"\n",
    "    det = dataset.get_detection(match.detection_id)\n",
    "    if det is None:\n",
    "        print(f'Detection {match.detection_id} not found')\n",
    "        return\n",
    "\n",
    "    gt = match.gt_annotation\n",
    "    coco_image = coco_loader._images[gt.image_uuid]\n",
    "    img_path = coco_loader.get_image_path(coco_image)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    plot_detection_vs_gt(det, gt, img, img_w, img_h, target_size, patch_size, ax=ax,\n",
    "                         title_extra=f'\\nidentity={gt.individual_id}  |  viewpoint={gt.viewpoint}')\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='lime', linewidth=2.5, label='GT bbox'),\n",
    "        Line2D([0], [0], color='dodgerblue', linewidth=2.5, linestyle='--', label='Detection bbox'),\n",
    "        Rectangle((0, 0), 1, 1, facecolor=(0.2, 0.8, 0.2), alpha=0.35, label='Patch inside GT'),\n",
    "        Rectangle((0, 0), 1, 1, facecolor=(0.8, 0.2, 0.2), alpha=0.35, label='Patch outside GT'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_all_candidates_for_gt(gt_uuid, coco_loader, dataset, target_size, patch_size, matched=None):\n",
    "    \"\"\"Show ALL candidate detections for a specific GT annotation UUID.\"\"\"\n",
    "    from src.evaluation.detection_matching import get_image_uuid_from_detection_id, _bboxes_overlap\n",
    "\n",
    "    # Find GT annotation\n",
    "    gt_ann = None\n",
    "    for ann in coco_loader.annotations:\n",
    "        if ann.uuid == gt_uuid:\n",
    "            gt_ann = ann\n",
    "            break\n",
    "    if gt_ann is None:\n",
    "        print(f'GT annotation {gt_uuid} not found')\n",
    "        return\n",
    "\n",
    "    print(f'GT: uuid={gt_ann.uuid}  identity={gt_ann.individual_id}  viewpoint={gt_ann.viewpoint}')\n",
    "    print(f'    bbox=({gt_ann.bbox.x1:.0f}, {gt_ann.bbox.y1:.0f}, {gt_ann.bbox.x2:.0f}, {gt_ann.bbox.y2:.0f})')\n",
    "\n",
    "    # Load the image once\n",
    "    coco_image = coco_loader._images[gt_ann.image_uuid]\n",
    "    img_path = coco_loader.get_image_path(coco_image)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # Find which detection was actually matched to this GT (if any)\n",
    "    matched_det_id = None\n",
    "    if matched is not None:\n",
    "        for m in matched:\n",
    "            if m.gt_annotation.uuid == gt_uuid:\n",
    "                matched_det_id = m.detection_id\n",
    "                break\n",
    "\n",
    "    # Find all detections on this image\n",
    "    all_det_ids = [\n",
    "        did for did in dataset._index['detection_to_batch']\n",
    "        if get_image_uuid_from_detection_id(did) == gt_ann.image_uuid\n",
    "    ]\n",
    "    print(f'{len(all_det_ids)} detections on this image')\n",
    "\n",
    "    # Load each detection, compute score, collect candidates\n",
    "    candidates = []\n",
    "    for det_id in all_det_ids:\n",
    "        det = dataset.get_detection(det_id)\n",
    "        if det is None:\n",
    "            continue\n",
    "        if not _bboxes_overlap(det.bbox, gt_ann.bbox):\n",
    "            continue\n",
    "\n",
    "        centers = patch_centers_in_image_space(\n",
    "            det.square_crop_bbox, det.patch_mask, img_w, img_h, target_size, patch_size\n",
    "        )\n",
    "        if not centers:\n",
    "            continue\n",
    "        n_inside = sum(1 for x, y in centers if _point_in_bbox(x, y, gt_ann.bbox))\n",
    "        score = n_inside / len(centers)\n",
    "        if score > 0:\n",
    "            candidates.append((det, score))\n",
    "\n",
    "    candidates.sort(key=lambda t: t[1], reverse=True)\n",
    "    print(f'{len(candidates)} candidate detections with overlap > 0\\n')\n",
    "\n",
    "    for rank, (det, score) in enumerate(candidates):\n",
    "        is_chosen = det.detection_id == matched_det_id\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "        plot_detection_vs_gt(det, gt_ann, img, img_w, img_h, target_size, patch_size, ax=ax,\n",
    "                             title_extra=f'  |  rank #{rank+1}' + ('  ** MATCHED **' if is_chosen else ''))\n",
    "        if is_chosen:\n",
    "            ax.patch.set_edgecolor('gold')\n",
    "            ax.patch.set_linewidth(4)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random match\n",
    "m = random.choice(matched)\n",
    "plot_match(m, dataset, coco_loader, target_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific match by index\n",
    "IDX = 0  # <-- change as needed\n",
    "plot_match(matched[IDX], dataset, coco_loader, target_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-matches",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 5 worst matches (lowest score) to find potential problems\n",
    "sorted_by_score = sorted(matched, key=lambda m: m.score)\n",
    "for m in sorted_by_score[:5]:\n",
    "    print(m.gt_annotation)\n",
    "    plot_match(m, dataset, coco_loader, target_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v1xx6ginc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_UUID = '81ab419c-6252-409c-b788-8b1e92113014'  # <-- change as needed\n",
    "show_all_candidates_for_gt(GT_UUID, coco_loader, dataset, target_size, patch_size, matched=matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sd95qxd6qb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where the top-1 candidate for this GT actually went\n",
    "GT_UUID = '6da70b81-0f70-418e-9ef5-581eb39537f0'\n",
    "\n",
    "from src.evaluation.detection_matching import get_image_uuid_from_detection_id, _bboxes_overlap\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "gt_ann = next(a for a in coco_loader.annotations if a.uuid == GT_UUID)\n",
    "coco_image = coco_loader._images[gt_ann.image_uuid]\n",
    "img_w, img_h = coco_image.width, coco_image.height\n",
    "\n",
    "all_det_ids = [\n",
    "    did for did in dataset._index['detection_to_batch']\n",
    "    if get_image_uuid_from_detection_id(did) == gt_ann.image_uuid\n",
    "]\n",
    "\n",
    "# Find best candidate\n",
    "best_det_id, best_n = None, 0\n",
    "for det_id in all_det_ids:\n",
    "    det = dataset.get_detection(det_id)\n",
    "    if det is None or not _bboxes_overlap(det.bbox, gt_ann.bbox):\n",
    "        continue\n",
    "    centers = patch_centers_in_image_space(\n",
    "        det.square_crop_bbox, det.patch_mask, img_w, img_h, target_size, patch_size\n",
    "    )\n",
    "    n_inside = sum(1 for x, y in centers if _point_in_bbox(x, y, gt_ann.bbox))\n",
    "    if n_inside > best_n:\n",
    "        best_n = n_inside\n",
    "        best_det_id = det_id\n",
    "\n",
    "print(f\"Top candidate: {best_det_id} with {best_n} patches inside GT {GT_UUID}\")\n",
    "\n",
    "# Which GT was this detection actually matched to?\n",
    "for m in matched:\n",
    "    if m.detection_id == best_det_id:\n",
    "        rival_gt = m.gt_annotation\n",
    "        print(f\"\\nIt was matched to GT {rival_gt.uuid} (score={m.score})\")\n",
    "        print(f\"  identity={rival_gt.individual_id}  viewpoint={rival_gt.viewpoint}\")\n",
    "        print(f\"  bbox=({rival_gt.bbox.x1:.0f}, {rival_gt.bbox.y1:.0f}, {rival_gt.bbox.x2:.0f}, {rival_gt.bbox.y2:.0f})\")\n",
    "\n",
    "        # IoU between the two GT bboxes\n",
    "        b1, b2 = gt_ann.bbox, rival_gt.bbox\n",
    "        xi1, yi1 = max(b1.x1, b2.x1), max(b1.y1, b2.y1)\n",
    "        xi2, yi2 = min(b1.x2, b2.x2), min(b1.y2, b2.y2)\n",
    "        inter = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "        union = b1.area() + b2.area() - inter\n",
    "        iou = inter / union if union > 0 else 0.0\n",
    "        print(f\"\\n  IoU between GT {GT_UUID} and GT {rival_gt.uuid}: {iou:.4f}\")\n",
    "\n",
    "        # Plot the match with BOTH GT bboxes\n",
    "        det = dataset.get_detection(best_det_id)\n",
    "        img = Image.open(coco_loader.get_image_path(coco_image)).convert('RGB')\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
    "        plot_detection_vs_gt(det, rival_gt, img, img_w, img_h, target_size, patch_size, ax=ax,\n",
    "                             title_extra=f'\\nRival GT {rival_gt.uuid}  |  Original GT {GT_UUID}  |  IoU={iou:.4f}')\n",
    "\n",
    "        # Draw the original GT bbox in orange\n",
    "        gx1, gy1, gx2, gy2 = gt_ann.bbox.x1, gt_ann.bbox.y1, gt_ann.bbox.x2, gt_ann.bbox.y2\n",
    "        ax.add_patch(Rectangle((gx1, gy1), gx2 - gx1, gy2 - gy1,\n",
    "                                fill=False, edgecolor='orange', linewidth=2.5, linestyle=':'))\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='lime', linewidth=2.5, label=f'Rival GT {rival_gt.uuid[:8]}...'),\n",
    "            Line2D([0], [0], color='orange', linewidth=2.5, linestyle=':', label=f'Original GT {GT_UUID[:8]}...'),\n",
    "            Line2D([0], [0], color='dodgerblue', linewidth=2.5, linestyle='--', label='Detection bbox'),\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=9)\n",
    "\n",
    "        # Expand view to include both GT bboxes\n",
    "        all_x = [gx1, gx2, rival_gt.bbox.x1, rival_gt.bbox.x2, det.bbox[0].item(), det.bbox[2].item()]\n",
    "        all_y = [gy1, gy2, rival_gt.bbox.y1, rival_gt.bbox.y2, det.bbox[1].item(), det.bbox[3].item()]\n",
    "        ax.set_xlim(min(all_x) - 50, max(all_x) + 50)\n",
    "        ax.set_ylim(max(all_y) + 50, min(all_y) - 50)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break\n",
    "else:\n",
    "    print(\"This detection was NOT matched to any GT (not in matched list)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17928800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271be40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e15b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}